---
title: "STAT 331 Portfolio"
author: "Eva Dykaar"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an \_A\_.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv: Lab 2 Q1`

```{r wd-1-csv}

surveys <- read_csv(here("Week 2", "surveys.csv"))
```

-   `xlsx`
-   Practice Act 4

```{r wd-1-xlsx}

military <- read_xlsx(here::here("gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending", 
                      skip = 7, 
                      n_max = 190)
```

-   `txt`
-   Practice Act 5.2

```{r wd-1-txt}

message <- read_csv(here::here("Week 5", "scrambled_message.txt")
                      )
```

**WD-2: I can select necessary columns from a dataset.**

Lab 3 Q9

```{r wd-2}

hiphop_clean |>
  distinct(subj, .keep_all = TRUE) |>
  select(sex, age, ethnic) |>
  summary()
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric
-   Lab 3 Q11

```{r wd-3-numeric}

belowtwenty <- hiphop_clean |>
  filter(age < 20)|>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))

```

-   character -- specifically a string
-   Lab 8 Step one: plurals (Practice act part of lab 8)

```{r wd-3-string}

pluralize_gift <- function(gift){

gift <- case_when(str_detect(string = gift, pattern = "y$") ~
            str_replace(string = gift, pattern = "y$", replace = "ies"), 
            str_detect(string = gift, pattern = "oo") ~ 
            str_replace(string = gift, pattern = "oo", replace = "ee"),
            TRUE ~ str_c(gift, "s"))

return(gift)

}
```

-   factor
-   Lab 3 Q12

```{r wd-3-factor}

non_white_women <- hiphop_clean |>
  filter(ethnic == "Non-White" & sex == "Female")|>
  mutate(familiarity = as.numeric(familiarity))|>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))
```

-   date
-   Practice Act 5.1 Q3

```{r wd-3-date}

thanks <- ymd("2018-11-22")

time_frame <- (thanks - days(35)) %--% (thanks + days(35))

suspects <- suspects %>%
  filter(Time.Spotted %within% time_frame)
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric
-   Lab 4 Q6

```{r wd-4-numeric}

avocado_ca <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")
         ) |>
  group_by(region, type) |>
  summarize(
    avg_price = mean(AveragePrice), .groups = "drop"
    ) |>
  pivot_wider(names_from = type, 
              values_from = avg_price) |>
  mutate(diff = organic - conventional)

avocado_ca

```

-   character -- specifically a string
-   Practice Act 5.2

```{r wd-4-string}

word <- str_replace_all(word, pattern = "aa", replace = "ee")
```

-   factor
-   Lab 3 Q7

```{r wd-4-factor}

hiphop_clean <- hiphop_clean|>
  mutate(ethnic = case_when(ethnic == "white" ~ "white", 
                            TRUE ~ "non-white"), 
                            ethnic = as.factor(ethnic))
```

-   date
-   Practice Act 5.1 Q4

```{r wd-4-date}

suspects <- suspects %>%
  mutate(iceland_time = with_tz(Time.Spotted, tz = "Etc/Greenwich")) %>%
  filter(pm(iceland_time))
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r wd-5-left}


```

-   `right_join()`
-   Preview Act 4.3 Q1

```{r wd-5-right}

right_join(prof_info, prof_course)
```

-   `inner_join()`
-   challenge 4

```{r wd-5-inner}
 # originally I used a full_join() in challenge 4 but I changed it to an inner_join() to show that I know how to use an inner_join() and I realized that this is normally a more severe method of joining data sets but because the data set I compiled included all the years and regions in the filtered avocado_clean() this did not change the data set from what the full_join() did.

avocado_ca2 <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")) |>
  inner_join(house_price, by = c("region", "year"))
```

-   `full_join()`
-   Challenge 4

```{r wd-5-full}

avocado_ca2 <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")) |>
  full_join(house_price, by = c("region", "year"))
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`
-   Lab 4 Q2

```{r wd-6-semi}

avocado_regions <- avocado |>
  semi_join(regions, by = "region")
```

-   `anti_join()`
-   Lab 4 Q2

```{r wd-6-anti}

avocado_clean <- avocado |>
  anti_join(regions, by = "region") |>
  anti_join(states, by = "region") |>
  anti_join(total, by = "region")

```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`
-   Lab 4 Q7

```{r wd-7-long}

avocado_ca2 <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")) |>
  pivot_longer(cols = c(`Small/medium`, Large, Xlarge),
               names_to = "Size",
               values_to = "amount") |>
  group_by(region, Size, type) |>
  summarize(avg_amount = mean(amount)) |>
  group_by(region, type) |>
  mutate(total = sum(avg_amount), 
         prop = avg_amount/total)
```

-   `pivot_wider()`
-   Lab 4 Q6

```{r wd-7-wide}

avocado_ca <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")
         ) |>
  group_by(region, type) |>
  summarize(
    avg_price = mean(AveragePrice), .groups = "drop"
    ) |>
  pivot_wider(names_from = type, 
              values_from = avg_price) |>
  mutate(diff = organic - conventional)

```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

Lab 2, Lab, 3, Lab 4, Challenge 4, Lab 8, Challenge 9

**R-2: I can write well documented and tidy code.**

-   Example 1
-   Lab 3 Q12

```{r r-2-1}

non_white_women <- hiphop_clean |>
  filter(ethnic == "Non-White" & sex == "Female")|>
  mutate(familiarity = as.numeric(familiarity))|>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))

```

-   Example 2
-   Challenge 4

```{r r-2-2}

ggplot(data = avocado_ca2, mapping = aes(x = years, y = region)) +
   geom_density_ridges(fill = "cadetblue") +
   labs(x = "Number of Years to Save Up", 
        y = "City",
        title = "How Long it Will Take to Save for a House")
```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1
-   Lab 3 Q11

```{r r-3-1}

belowtwenty <- hiphop_clean |>
  filter(age < 20)|>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))

```

-   Example 2
-   Lab 8 Step 2: Creating Sentences(Practice Act Part of Lab 8)

```{r r-3-2}

make_phrase <- function(day, num_word, item, verb, adjective, location) {
  
  ## Step 1: Replace NAs with blank strings
  verb <- str_replace_na(verb, "")
  adjective <- str_replace_na(adjective, "")
  location <- str_replace_na(location, "")
  
  ## Step 2: If the day is larger than 1, the items need pluralized! 
  item <- case_when(
    day > 1 ~ pluralize_gift(item),
    TRUE ~ item
  )
  
## Step 3: If the day is 1, you need to add an "a" or "an" before the gift
  a <- case_when(
    day == 1 & str_detect(string = item, pattern = "^aeiou") ~ "an",
    day == 1 ~ "a",
    TRUE ~ ""
  )
  num_word <- case_when(day == 1 ~ "",
                        TRUE ~ num_word)

  ## Step 4: Glue all of the pieces together to make a phrase!
  return(glue("{a} {num_word} {adjective} {item} {verb} {location}"))
}
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables
-   Lab 9 Q6

```{r dvs-1-num}

allison_f_lm |> 
  broom::augment() |> 
  ggplot(mapping = aes(y = .resid, x = .fitted)) +
  geom_point(color = "navy") +
  labs(x = "Fitted Values", y = "Residual Values", 
       title = "Plotted Residuals vs Fitted values")

```

-   numeric variables and categorical variables
-   Challenge 4

```{r dvs-2-num-cat}

ggplot(data = avocado_ca2, mapping = aes(x = years, y = region)) +
   geom_density_ridges(fill = "cadetblue") +
   labs(x = "Number of Years to Save Up", 
        y = "City",
        title = "How Long it Will Take to Save for a House")
```

-   categorical variables
-   Lab 5, Captures over the Week Q2

```{r dvs-2-cat}

# Source for how to rearrange the weekdays: https://www.reddit.com/r/rprogramming/comments/ue3aa0/ggplot_inquiry_how_can_i_arrange_weekdays_to/

surveys2 <- surveys |>
  mutate(day_of_week = as.factor(day_of_week), 
         day_of_week = fct_relevel(day_of_week, 
                                   "Mon", "Tue", "Wed",
                                      "Thu", "Fri", "Sat", 
                                      "Sun"))

  

ggplot(data = surveys2, mapping = aes(x = day_of_week)) +  
  geom_bar() + 
  labs(x = "Day of Week", y = " ", 
       title = "Number of Rodents Captured by Day")
```

-   dates
-   Lab 5 Time series plot Q4

```{r dvs-2-date}

surveys1 <- surveys |>
  group_by(genus, year) |>
  mutate(mean_weight = mean(weight))

ggplot(data = surveys1, mapping = aes(x = year, 
                                     y = mean_weight,
                                     color = fct_reorder(genus, 
                                                         mean_weight, .desc = TRUE))) +  
  geom_line(stat = "identity") +
  labs(x = "Year", y = " ",
       title = "Time Series Genus of Rodent by Weight(grams)",
       col = "Genus")
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1
-   Lab 4 Q7

```{r dvs-2-1}

avocado_ca2 <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")) |>
  pivot_longer(cols = c(`Small/medium`, Large, Xlarge),
               names_to = "Size",
               values_to = "amount") |>
  group_by(region, Size, type) |>
  summarize(avg_amount = mean(amount)) |>
  group_by(region, type) |>
  mutate(total = sum(avg_amount), 
         prop = avg_amount/total)

ggplot(data = avocado_ca2,
       mapping = aes(x = region,
                     y = prop, 
                     fill = factor(Size,
                            levels = c("Small/medium",
                                       "Large",
                                       "Xlarge")))) +
  facet_wrap(~type) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#a6cee3",
                               "#1f78b4", 
                               "#b2df8a")) +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  labs(x = "Region of CA",
       y = "Proportion of Mean Avocados Sold", 
       title = "Size of Avocados Sold by City",
       fill = "Size")

```

-   Example 2
-   Challenge 4

```{r dvs-2-2}

ggplot(data = avocado_ca2, mapping = aes(x = years, y = region)) +
   geom_density_ridges(fill = "cadetblue") +
   labs(x = "Number of Years to Save Up", 
        y = "City",
        title = "How Long it Will Take to Save for a House")
```

**DVS-3: I show creativity in my visualizations**

-   Example 1
-   Challenge 4

```{r dvs-3-1}

ggplot(data = avocado_ca2, mapping = aes(x = years, y = region)) +
   geom_density_ridges(fill = "cadetblue") +
   labs(x = "Number of Years to Save Up", 
        y = "City",
        title = "How Long it Will Take to Save for a House")
```

-   Example 2
-   Lab 4 Q6

```{r dvs-3-2}

avocado_ca <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")
         ) |>
  group_by(region, type) |>
  summarize(
    avg_price = mean(AveragePrice), .groups = "drop"
    ) |>
  pivot_wider(names_from = type, 
              values_from = avg_price) |>
  mutate(diff = organic - conventional)

avocado_ca


ggplot(data = avocado_ca, mapping = aes(x = diff, y = region)) +
  geom_segment(aes(xend = 0, yend = region)) +
  geom_point() +
  labs(x = "California City", 
       y = "Price Difference($)",
       title = "Organic v Conventional Avocado Price Difference by City")
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1
-   Lab 3 Q11

```{r dvs-4-1}

belowtwenty <- hiphop_clean |>
  filter(age < 20)|>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))

belowtwenty |>
  slice_max(mean_familiarity)
  
belowtwenty |>
  slice_min(mean_familiarity)
```

-   Example 2
-   Lab 4 Q5

```{r dvs-4-2}

options(scipen = 999)

top_5 <- avocado_clean |>
  group_by(region) |>
  summarize(avg_vol = mean(`Total Volume`)) |>
  slice_max(avg_vol, n = 5)

avocado_clean |>
  semi_join(top_5, by = "region") |>
  ggplot(mapping = aes(x = `Total Volume`,
                                   y = region)) +
  geom_boxplot(fill = "lightpink") +
  labs(x = "Total Volume", y = "Metro Area Regions", title = "Total Avocado Volume by Region")
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1
-   Challenge 3

```{r dvs-5-1}
# revised to use the new syntax of across

newhiphop <- hiphop_clean |>
  select(c(sex, ethnic, intl:unclassifiable))

newhiphop_sex <- newhiphop |>
  group_by(sex) |>
  summarise(
    across(.cols = intl:unclassifiable, 
      .fns = ~ mean(.x), 
      na.rm = TRUE
      )
    )
    
newhiphop_sex <- newhiphop_sex |>
  summarise(
    abs(
    across(.cols = intl:unclassifiable,
      .fns = ~ diff(.x), na.rm = TRUE
    )
  )
  )
newhiphop_sex |>
  which.max()
```

-   Example 2
-   Challenge 3

```{r dvs-5-2}
# revised to use the new syntax of across

newhiphop_ethnic <- newhiphop |>
  group_by(ethnic) |>
  summarise(
    across(
      .cols = intl:unclassifiable, 
      .fns = ~ mean(.x), 
      na.rm = TRUE
      )
    )

newhiphop_ethnic <- newhiphop_ethnic |>
  summarise(
    abs(
    across(
      .cols = intl:unclassifiable,
      .fns = ~ diff(.x), na.rm = TRUE
    )
  )
  )

newhiphop_ethnic |>
  which.max()
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1
-   Challenge 9 Q9

```{r dvs-6-1}

allen |>
  filter(Year == "2000", State %in% c("PA", "CA")) |>
  pivot_wider(names_from = Name, values_from = Count, values_fill = 0) |>
  select(State, Alan, Allen, Allan) |>
  gt() |>
  tab_header(title = "Number of Alan, Allen, or Allan by State")

```

-   Example 2
-   Challenge 9 Q10

```{r dvs-6-2}

allen |> 
  filter(Year == "2000", State %in% c("PA", "CA")) |>
  mutate(prop = Count / sum(Count)
         ) |>
  select(Sex, State, Name, prop) |>
  pivot_wider(names_from = Name, values_from = prop, values_fill = 0) |>
  gt() |>
  tab_header(title = "Percentage of Alan, Allen, or Allan by State") |>
  fmt_percent(columns = 3:5, decimals = 2)

```

**DVS-7: I show creativity in my tables.**

-   Example 1
-   Challenge 9 Q1

```{r dvs-7-1}

names |>
  filter(Name == "Allison") |>
  group_by(State, Sex) |>
  summarize(Count = sum(Count), .groups = "drop") |>
  pivot_wider(names_from = Sex, values_from = Count, values_fill = 0) |>
  knitr::kable(format = "html", 
               digits = 3, 
               col.names = 
                 c("State", 
                   "Female", 
                   "Male"),
               caption = "Number of People Named Allison by Sex and State") |>
  kable_styling(font_size = 15, bootstrap_options = "striped")

```

-   Example 2

```{r dvs-7-2}

#Have not learned yet
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call
-   Lab 4 Q2

```{r pe-1-one-call}

avocado <- avocado |>
  rename("Small/medium" = "4046", "Large" = "4225", "Xlarge" = "4770")
```

-   `across()`
-   Lab 7 Part one Q1

```{r pe-1-across}

fish |>
  summarize(
    across(.cols = trip:species, 
          .fns = ~ sum(is.na(.x)))
  )

```

-   `map()` functions
-   Lab 8 step 4: using the functions

```{r pe-1-map-1}

song <- map_chr(.x = 1:12, 
               .f = ~ sing_day(dataset = xmas2, num = .x, phrase_col = Full.Phrase))

song

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1
- Lab 8 Step 3: Iteration

```{r pe2-1}

sing_day <- function(dataset, num, phrase_col){
  
  # Step 1: Setup the intro line
  # Hint: You need to convert a number (e.g., 1) to a word (e.g., first)
  num_word <- ordinal(num)
  
  intro <- glue::glue("On the {num_word} day of Christmas, my true love sent to me")
  
  # Step 2: Sing the gift phrases

    phrases <- dataset |>
      pull( {{phrase_col}} )

  lyrics <- str_flatten(phrases[num:1])
  
  ## put it together
  return(glue::glue("{intro} {lyrics}"))


}
```

-   Example 2
- Lab 7 Incorporating variables

```{r pe2-2}

rescale_column <- function(data, variables) {
  
  stopifnot(is.data.frame(data))
  
  data <- data |>
    mutate(across(.cols = {{variables}}, 
                  ~ rescale_01(.x))
                  )
  
  data
}
```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`
-   Challenge 3

```{r pe-3-across}
# revised to use the new syntax of across

newhiphop_ethnic <- newhiphop |>
  group_by(ethnic) |>
  summarise(
    across(
      .cols = intl:unclassifiable, 
      .fns = ~ mean(.x), 
      na.rm = TRUE
      )
    )

newhiphop_ethnic <- newhiphop_ethnic |>
  summarise(
    abs(
    across(
      .cols = intl:unclassifiable,
      .fns = ~ diff(.x), na.rm = TRUE
    )
  )
  )

newhiphop_ethnic |>
  which.max()
```

-   `map()` functions (Provide 2 Examples)
-   Practice Activity part of Lab 8 (Test your function)

```{r pe-3-map-1}

xmas2 <- xmas %>%
  mutate(day.num = as.character(english::english(Day)),
         
    Full.Phrase = pmap_chr(.l = list(
      day = Day,
      num_word = day.num,
      item = Gift.Item,
      verb = Verb,
      adjective = Adjective,
      location = Location), 
    .f = make_phrase)
  )
```

-   Lab 8: Step 4: Using your functions!

```{r pe-3-map-2}

song <- map_chr(.x = 1:12, 
               .f = ~ sing_day(dataset = xmas2, num = .x, phrase_col = Full.Phrase))

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1
-   Challenge 3

```{r pe-4-1}

# revised to use the new syntax of across

newhiphop_ethnic <- newhiphop |>
  group_by(ethnic) |>
  summarise(
    across(
      .cols = intl:unclassifiable, 
      .fns = ~ mean(.x), 
      na.rm = TRUE
      )
    )

newhiphop_ethnic <- newhiphop_ethnic |>
  summarise(
    abs(
    across(
      .cols = intl:unclassifiable,
      .fns = ~ diff(.x), na.rm = TRUE
    )
  )
  )

newhiphop_ethnic |>
  which.max()
```

-   Example 2
-   Lab 4 Q6

```{r pe-4-2}

avocado_ca <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")
         ) |>
  group_by(region, type) |>
  summarize(
    avg_price = mean(AveragePrice), .groups = "drop"
    ) |>
  pivot_wider(names_from = type, 
              values_from = avg_price) |>
  mutate(diff = organic - conventional)

avocado_ca


ggplot(data = avocado_ca, mapping = aes(x = diff, y = region)) +
  geom_segment(aes(xend = 0, yend = region)) +
  geom_point() +
  labs(x = "California City", 
       y = "Price Difference($)",
       title = "Organic v Conventional Avocado Price Difference by City")

```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1
-   Practice Act 9.2

```{r dsm-1-1}

set.seed(1957)

music_man <- function(n_tromb, n_cor, n_reed){
  
  trombones <- rnorm(n_tromb, mean = 4.6, sd = 0.8)
  cornets <- runif(n_cor, min = 1.5, max = 3.5)
  reeds <- rchisq(n_reed, df = 4)
  
  return(sum(c(trombones, cornets, reeds)))
  
}

my_weights <- map_dbl(.x = 1:1000, 
                      .f = ~ music_man(n_tromb = 76, 
                                       n_cor = 110, 
                                       n_reed = 1035)
                      ) 
sum(my_weights <4532)
```

-   Example 2
-   Practice Act 9.2 Warm up

```{r dsm-1-2}

qunif(p = .95, min = 1.5, max = 3.5)

```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

-   Example 1
- Lab 9 Q5

```{r dsm-2-1}

allison_f_lm <- allison_f |>
  group_by(Year) |>
  summarize(Count = sum(Count)) |>
  lm(Count ~ Year, data = _)

```

-   Example 2
- Practice Act 9.1

```{r dsm-2-2}

animal_lm <- animal |>
  lm(weight_after ~ weight_before, data = _)

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

For the previous weeks I have taken the feedback given to me on the lab and challenges and resubmitted it for a complete if any questions have an incomplete on it. I also have re-submitted the week 3, 4, and 5 labs and I just have one question to correct on lab 3. I have looked over the feedback I have received and incorporated it into future labs at any points possible to make sure I do not make the same mistake again. For example, before resubmitting Lab 4 I changed my bar plot to a Cleveland dot plot because that data was differences not counts. I also read the feedback from the peer reviews and have taken what they have said into account. I think that I have revised my thinking on the code examples that I have provided in my portfolio because most of the examples I figured out on my second try and I needed to shift my way of thinking to get my code to be as efficient and tidy as it can be.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

For week 1 and week 2 I do not think I went above and beyond with external sources because it was not until week 3 that we as a class set up the expectations for what an A is in this class. For Lab 3 I did not make use of external research so I knew for lab 4 I really needed to go above and beyond and use external research, which is exactly what I did. I first brought back what I learned in challenge 1 and changed the font of the entire html file to "garet", and I did this for both lab 4 and challenge 4. For lab 4 I also used external research to find what the avocado code names mean to clean my data, stopped my graph from using scientific notation because I thought it made my graph look more tidy, did outside research to figure out why my bar chart was not running, I changed the order of my legend, the color of my graph, and staggered the labels on my axis so they did not overlap. For challenge 4 I found data online from Zillow and created an excel file from this data to join together with the avocado data. In addition I used density plots which was extending my thinking from challenge 2. I think that I have demonstrated a commitment to continued learning because I have added in many extra pieces to my lab 4 and challenge 4 to make up for not extending my thinking as much as I could have in lab 3. While extending my thinking it required me to learn more about different functions. For lab 5 I extended my thinking because I did outside research on the forcats library and how to use different functions like fct_reorder(), fct_relevel(), and fct_collapse(). Many of the examples I included in this portfolio are from code chunks where I extended my thinking.

## Peer Support & Collaboration

<!-- Include an image of feedback you gave that you are proud of (either in a peer review or in Discord) -->

![](images/image-1621592884.png){width="271"}

![](images/image-1441920820.png){width="266"}

An image of the peer review is also included under the supporting artifacts.
