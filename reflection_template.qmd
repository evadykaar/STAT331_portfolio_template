---
title: "STAT 331 Portfolio"
author: "Eva Dykaar"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an \_A\_.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv: Lab 2 Q1`

```{r wd-1-csv}

surveys <- read_csv(here("Week 2", "surveys.csv"))
```

-   `xlsx`
-   Practice Act 4

```{r wd-1-xlsx}

military <- read_xlsx(here::here("gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending", 
                      skip = 7, 
                      n_max = 190)
```

-   `txt`
-   Practice Act 5.2

```{r wd-1-txt}

message <- read_csv(here::here("Week 5", "scrambled_message.txt")
                      )
```

**WD-2: I can select necessary columns from a dataset.**

Lab 3 Q9

```{r wd-2}

hiphop_clean |>
  distinct(subj, .keep_all = TRUE) |>
  select(sex, age, ethnic) |>
  summary()
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric
-   Lab 3 Q11

```{r wd-3-numeric}

belowtwenty <- hiphop_clean |>
  filter(age < 20)|>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))

belowtwenty |>
  slice_max(mean_familiarity)
  
belowtwenty |>
  slice_min(mean_familiarity)

```

-   character -- specifically a string
-   Practice Act 5.2

```{r wd-3-string}

word <- str_remove_all(word, pattern = "ugh*[:punct:]")
```

-   factor
-   Lab 3 Q12

```{r wd-3-factor}

non_white_women <- hiphop_clean |>
  filter(ethnic == "Non-White" & sex == "Female")|>
  mutate(familiarity = as.numeric(familiarity))|>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))
```

-   date
-   Practice Act 5.1 Q3

```{r wd-3-date}

thanks <- ymd("2018-11-22")

time_frame <- (thanks - days(35)) %--% (thanks + days(35))

suspects <- suspects %>%
  filter(Time.Spotted %within% time_frame)
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric
-   Lab 4 Q6

```{r wd-4-numeric}


avocado_ca <- avocado_clean |>
  filter(region == c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")
         ) |>
  group_by(region, type) |>
  summarize(
    avg_price = mean(AveragePrice)
    ) |>
  pivot_wider(names_from = type, 
              values_from = avg_price) |>
  mutate(diff = organic - conventional)

avocado_ca |>
  summary()
```

-   character -- specifically a string
-   Practice Act 5.2

```{r wd-4-string}

word <- str_replace_all(word, pattern = "aa", replace = "ee")
```

-   factor
-   Lab 3 Q7

```{r wd-4-factor}

hiphop_clean <- hiphop_clean|>
  mutate(ethnic = case_when(ethnic == "white" ~ "white", 
                            TRUE ~ "non-white"), 
                            ethnic = as.factor(ethnic))
```

-   date
-   Practice Act 5.1 Q4

```{r wd-4-date}

suspects <- suspects %>%
  mutate(iceland_time = with_tz(Time.Spotted, tz = "Etc/Greenwich")) %>%
  filter(pm(iceland_time))
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r wd-5-left}


```

-   `right_join()`
-   Preview Act 4.3 Q1

```{r wd-5-right}

right_join(prof_info, prof_course)
```

-   `inner_join()`
-   challenge 4

```{r wd-5-inner}
 # origionally I used a full_join() in challenge 4 but I changed it to an inner_join() to show that I know how to use an inner_join() and I realized that this is normally a more severe method of joining data sets but because the data set I compiled included all the years and regions in the filtered avocado_clean() this did not change the data set from what the full_join() did.

avocado_ca2 <- avocado_clean |>
  filter(region == c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")) |>
  inner_join(house_price, by = c("region", "year"))
```

-   `full_join()`
-   Challenge 4

```{r wd-5-full}

avocado_ca2 <- avocado_clean |>
  filter(region == c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")) |>
  full_join(house_price, by = c("region", "year"))
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`
-   Lab 4 Q2

```{r wd-6-semi}

avocado_regions <- avocado |>
  semi_join(regions, by = "region")
```

-   `anti_join()`
-   Lab 4 Q2

```{r wd-6-anti}

avocado_clean <- avocado |>
  anti_join(regions, by = "region") |>
  anti_join(states, by = "region") |>
  anti_join(total, by = "region")

```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`
-   Lab 4 Q7

```{r wd-7-long}

avocado_ca2 <- avocado_clean |>
  filter(region == c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")) |>
  pivot_longer(cols = c(`Small/medium`, Large, Xlarge),
               names_to = "Size",
               values_to = "amount") |>
  group_by(region, Size, type) |>
  summarize(avg_amount = mean(amount)) |>
  group_by(region, type) |>
  mutate(total = sum(avg_amount)) |>
  mutate(prop = avg_amount/total)
```

-   `pivot_wider()`
-   Lab 4 Q6

```{r wd-7-wide}

avocado_ca <- avocado_clean |>
  filter(region == c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")
         ) |>
  group_by(region, type) |>
  summarize(
    avg_price = mean(AveragePrice)
    ) |>
  pivot_wider(names_from = type, 
              values_from = avg_price) |>
  mutate(diff = organic - conventional)
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

Lab 2, Lab, 3, Lab 4, Challenge 4

**R-2: I can write well documented and tidy code.**

-   Example 1
-   Lab 3 Q12

```{r r-2-1}

non_white_women <- hiphop_clean |>
  filter(ethnic == "Non-White" & sex == "Female")|>
  mutate(familiarity = as.numeric(familiarity))|>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))

non_white_women |>
  slice_max(mean_familiarity)
  
non_white_women |>
  slice_min(mean_familiarity)
```

-   Example 2
-   Challenge 4

```{r r-2-2}

ggplot(data = avocado_ca2, mapping = aes(x = years, y = region)) +
   geom_density_ridges(fill = "cadetblue") +
   labs(x = "Number of Years to Save Up", 
        y = "City",
        title = "How Long it Will Take to Save for a House")
```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1
-   Lab 3 Q11

```{r r-3-1}

belowtwenty <- hiphop_clean |>
  filter(age < 20)|>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))

belowtwenty |>
  slice_max(mean_familiarity)
  
belowtwenty |>
  slice_min(mean_familiarity)
```

-   Example 2
-   Lab 4 Q4

```{r r-3-2}

avocado_clean <- avocado_clean |>
  separate("Date", into = c("year", "month", "day"), sep = "-")
  
avocado_clean |>  
  slice_max(`Total Volume`) |>
  pull(month)
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables
-   Challenge 1

```{r dvs-1-num}

plot(pressure, xlab = ' Temperature (deg C)', ylab = 'Pressure (mm)')
```

-   numeric variables and categorical variables
-   Challenge 4

```{r dvs-2-num-cat}

ggplot(data = avocado_ca2, mapping = aes(x = years, y = region)) +
   geom_density_ridges(fill = "cadetblue") +
   labs(x = "Number of Years to Save Up", 
        y = "City",
        title = "How Long it Will Take to Save for a House")
```

-   categorical variables
-   Lab 5, Captures over the Week Q2

```{r dvs-2-cat}

# Source for how to rearrange the weekdays: https://www.reddit.com/r/rprogramming/comments/ue3aa0/ggplot_inquiry_how_can_i_arrange_weekdays_to/

surveys2 <- surveys |>
  mutate(day_of_week = as.factor(day_of_week), 
         day_of_week = fct_relevel(day_of_week, 
                                   "Mon", "Tue", "Wed",
                                      "Thu", "Fri", "Sat", 
                                      "Sun"))

  

ggplot(data = surveys2, mapping = aes(x = day_of_week)) +  
  geom_bar() + 
  labs(x = "Day of Week", y = " ", 
       title = "Number of Rodents Captured by Day")
```

-   dates
-   Lab 5 Time series plot Q4

```{r dvs-2-date}

surveys1 <- surveys |>
  group_by(genus, year) |>
  mutate(mean_weight = mean(weight))

ggplot(data = surveys1, mapping = aes(x = year, 
                                     y = mean_weight,
                                     color = fct_reorder(genus, 
                                                         mean_weight, .desc = TRUE))) +  
  geom_line(stat = "identity") +
  labs(x = "Year", y = " ",
       title = "Time Series Genus of Rodent by Weight(grams)",
       col = "Genus")
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1
-   Lab 4 Q7

```{r dvs-2-1}

avocado_ca2 <- avocado_clean |>
  filter(region == c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")) |>
  pivot_longer(cols = c(`Small/medium`, Large, Xlarge),
               names_to = "Size",
               values_to = "amount") |>
  group_by(region, Size, type) |>
  summarize(avg_amount = mean(amount)) |>
  group_by(region, type) |>
  mutate(total = sum(avg_amount)) |>
  mutate(prop = avg_amount/total)

ggplot(data = avocado_ca2,
       mapping = aes(x = region,
                     y = prop, 
                     fill = factor(Size,
                            levels = c("Small/medium",
                                       "Large",
                                       "Xlarge")))) +
  facet_wrap(~type) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#a6cee3",
                               "#1f78b4", 
                               "#b2df8a")) +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  labs(x = "Region of CA",
       y = "Proportion of Mean Avocados Sold", 
       title = "Size of Avocados Sold by City",
       fill = "Size")

```

-   Example 2
-   Challenge 4

```{r dvs-2-2}

ggplot(data = avocado_ca2, mapping = aes(x = years, y = region)) +
   geom_density_ridges(fill = "cadetblue") +
   labs(x = "Number of Years to Save Up", 
        y = "City",
        title = "How Long it Will Take to Save for a House")
```

**DVS-3: I show creativity in my visualizations**

-   Example 1
-   Challenge 4

```{r dvs-3-1}

ggplot(data = avocado_ca2, mapping = aes(x = years, y = region)) +
   geom_density_ridges(fill = "cadetblue") +
   labs(x = "Number of Years to Save Up", 
        y = "City",
        title = "How Long it Will Take to Save for a House")
```

-   Example 2
-   Lab 4 Q6

```{r dvs-3-2}

avocado_ca <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")
         ) |>
  group_by(region, type) |>
  summarize(
    avg_price = mean(AveragePrice), .groups = "drop"
    ) |>
  pivot_wider(names_from = type, 
              values_from = avg_price) |>
  mutate(diff = organic - conventional)

avocado_ca


ggplot(data = avocado_ca, mapping = aes(x = diff, y = region)) +
  geom_segment(aes(xend = 0, yend = region)) +
  geom_point() +
  labs(x = "California City", 
       y = "Price Difference($)",
         title = "Organic v Conventional Avocado Price Difference by City")
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1
-   Lab 3 Q11

```{r dvs-4-1}

belowtwenty <- hiphop_clean |>
  filter(age < 20)|>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_familiarity = mean(familiarity))

belowtwenty |>
  slice_max(mean_familiarity)
  
belowtwenty |>
  slice_min(mean_familiarity)
```

-   Example 2
-   Lab 4 Q5

```{r dvs-4-2}

options(scipen = 999)

top_5 <- avocado_clean |>
  group_by(region) |>
  summarize(avg_vol = mean(`Total Volume`)) |>
  slice_max(avg_vol, n = 5)

avocado_clean |>
  semi_join(top_5, by = "region") |>
  ggplot(mapping = aes(x = `Total Volume`,
                                   y = region)) +
  geom_boxplot(fill = "lightpink") +
  labs(x = "Total Volume", y = "Metro Area Regions", title = "Total Avocado Volume by Region")
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1
-   Challenge 3

```{r dvs-5-1}

newhiphop <- hiphop_clean |>
  select(c(sex, ethnic, intl:unclassifiable))

newhiphop_sex <- newhiphop |>
  group_by(sex) |>
  summarise(
    across(
      intl:unclassifiable, 
      mean, 
      na.rm = TRUE
      )
    )
    
newhiphop_sex <- newhiphop_sex |>
  summarise(
    abs(
    across(
      intl:unclassifiable,
      diff, na.rm = TRUE
    )
  )
  )
newhiphop_sex |>
  which.max()
```

-   Example 2
-   Challenge 3

```{r dvs-5-2}

newhiphop_ethnic <- newhiphop |>
  group_by(ethnic) |>
  summarise(
    across(
      intl:unclassifiable, 
      mean, 
      na.rm = TRUE
      )
    )

newhiphop_ethnic <- newhiphop_ethnic |>
  summarise(
    abs(
    across(
      intl:unclassifiable,
      diff, na.rm = TRUE
    )
  )
  )

newhiphop_ethnic |>
  which.max()
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r dvs-6-1}

# Have not learned yet
```

-   Example 2

```{r dvs-6-2}

# Have not learned yet
```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r dvs-7-1}
# Have not learned yet
```

-   Example 2

```{r dvs-7-2}

#Have not learned yet
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call
-   Lab 4 Q2

```{r pe-1-one-call}

avocado <- avocado |>
  rename("Small/medium" = "4046", "Large" = "4225", "Xlarge" = "4770")
```

-   `across()`
-   Challenge 3

```{r pe-1-across}

newhiphop <- hiphop_clean |>
  select(c(sex, ethnic, intl:unclassifiable))

newhiphop_sex <- newhiphop |>
  group_by(sex) |>
  summarise(
    across(
      intl:unclassifiable, 
      mean, 
      na.rm = TRUE
      )
    )
    
newhiphop_sex <- newhiphop_sex |>
  summarise(
    abs(
    across(
      intl:unclassifiable,
      diff, na.rm = TRUE
    )
  )
  )
newhiphop_sex |>
  which.max()
```

-   `map()` functions

```{r pe-1-map-1}

# Have not learned yet
```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1

```{r pe2-1}

# Have not learned yet
```

-   Example 2

```{r pe2-2}

# Have not learned yet
```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`
-   Challenge 3

```{r pe-3-across}

newhiphop_ethnic <- newhiphop |>
  group_by(ethnic) |>
  summarise(
    across(
      intl:unclassifiable, 
      mean, 
      na.rm = TRUE
      )
    )

newhiphop_ethnic <- newhiphop_ethnic |>
  summarise(
    abs(
    across(
      intl:unclassifiable,
      diff, na.rm = TRUE
    )
  )
  )

newhiphop_ethnic |>
  which.max()
```

-   `map()` functions (Provide 2 Examples)

```{r pe-3-map-1}

# Have not learned yet
```

```{r pe-3-map-2}

# Have not learned yet
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1
-   Challenge 3

```{r pe-4-1}

newhiphop_ethnic <- newhiphop |>
  group_by(ethnic) |>
  summarise(
    across(
      intl:unclassifiable, 
      mean, 
      na.rm = TRUE
      )
    )

newhiphop_ethnic <- newhiphop_ethnic |>
  summarise(
    abs(
    across(
      intl:unclassifiable,
      diff, na.rm = TRUE
    )
  )
  )

newhiphop_ethnic |>
  which.max()
```

-   Example 2
-   Lab 4 Q6

```{r pe-4-2}

avocado_ca <- avocado_clean |>
  filter(region %in% c("LosAngeles",
                    "SanDiego",
                    "Sacramento",
                    "SanFrancisco")
         ) |>
  group_by(region, type) |>
  summarize(
    avg_price = mean(AveragePrice), .groups = "drop"
    ) |>
  pivot_wider(names_from = type, 
              values_from = avg_price) |>
  mutate(diff = organic - conventional)

avocado_ca


ggplot(data = avocado_ca, mapping = aes(x = diff, y = region)) +
  geom_segment(aes(xend = 0, yend = region)) +
  geom_point() +
  labs(x = "California City", 
       y = "Price Difference($)",
         title = "Organic v Conventional Avocado Price Difference by City")

```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r dsm-1-1}

# Have not learned yet
```

-   Example 2

```{r dsm-1-2}

# Have not learned yet
```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

-   Example 1

```{r dsm-2-1}

# Have not learned yet
```

-   Example 2

```{r dsm-2-2}

# Have not learned yet
```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

For the previous weeks I have taken the feedback given to me on the lab and challenges and resubmitted it for a complete if any questions have an incomplete on it. I also have re-submitted the week 3, 4, and 5 labs and I just have one question to correct on lab 3. I have looked over the feedback I have received and incorporated it into future labs at any points possible to make sure I do not make the same mistake again. For example, before resubmitting Lab 4 I changed my bar plot to a Cleveland dot plot because that data was differences not counts. I also read the feedback from the peer reviews and have taken what they have said into account. I think that I have revised my thinking on the code examples that I have provided in my portfolio because most of the examples I figured out on my second try and I needed to shift my way of thinking to get my code to be as efficient and tidy as it can be.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

For week 1 and week 2 I do not think I went above and beyond with external sources because it was not until week 3 that we as a class set up the expectations for what an A is in this class. For Lab 3 I did not make use of external research so I knew for lab 4 I really needed to go above and beyond and use external research, which is exactly what I did. I first brought back what I learned in challenge 1 and changed the font of the entire html file to "garet", and I did this for both lab 4 and challenge 4. For lab 4 I also used external research to find what the avocado code names mean to clean my data, stopped my graph from using scientific notation because I thought it made my graph look more tidy, did outside research to figure out why my bar chart was not running, I changed the order of my legend, the color of my graph, and staggered the labels on my axis so they did not overlap. For challenge 4 I found data online from Zillow and created an excel file from this data to join together with the avocado data. In addition I used density plots which was extending my thinking from challenge 2. I think that I have demonstrated a commitment to continued learning because I have added in many extra pieces to my lab 4 and challenge 4 to make up for not extending my thinking as much as I could have in lab 3. While extending my thinking it required me to learn more about different functions. For lab 5 I extended my thinking because I did outside research on the forcats library and how to use different functions like fct_reorder(), fct_relevel(), and fct_collapse(). Many of the examples I included in this portfolio are from code chunks where I extended my thinking.

## Peer Support & Collaboration

<!-- Include an image of feedback you gave that you are proud of (either in a peer review or in Discord) -->

![](images/image-1621592884.png){width="271"}

![](images/image-1441920820.png){width="266"}

Images also included under the supporting artifacts.
